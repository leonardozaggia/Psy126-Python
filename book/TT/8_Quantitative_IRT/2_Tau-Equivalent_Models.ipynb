{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e332052a",
   "metadata": {},
   "source": [
    "# 6.2 Tau-Equivalent Models\n",
    "## Essentially Tau-Equivalent Model\n",
    "\n",
    "The **Essentially tau-equivalent** measurement model is also quite flexible but it has one more restriction compared to the **Tau Congeneric** measurement model. It assumes that\n",
    "\n",
    "* items differ in their difficulty\n",
    "* items **are equivalent in their discrimination power**\n",
    "* items are differently reliable  \n",
    "\n",
    "We therefore get an estimate for the intercepts (`Intecepts` section) and for the errors (`Variances` section). Note that we also get a `Latent Variables` section again, however, you will have to fix all the loadings to 1.\n",
    "\n",
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 12 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        13\n",
      "\n",
      "  Number of observations                           238\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                                16.949\n",
      "  Degrees of freedom                                14\n",
      "  P-value (Chi-square)                           0.259\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               435.847\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.993\n",
      "  Tucker-Lewis Index (TLI)                       0.992\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -435.870\n",
      "  Loglikelihood unrestricted model (H1)       -427.396\n",
      "                                                      \n",
      "  Akaike (AIC)                                 897.740\n",
      "  Bayesian (BIC)                               942.880\n",
      "  Sample-size adjusted Bayesian (SABIC)        901.674\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.030\n",
      "  90 Percent confidence interval - lower         0.000\n",
      "  90 Percent confidence interval - upper         0.073\n",
      "  P-value H_0: RMSEA <= 0.050                    0.737\n",
      "  P-value H_0: RMSEA >= 0.080                    0.023\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.053\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  eta =~                                                                \n",
      "    item_1            1.000                               0.253    0.682\n",
      "    item_2            1.000                               0.253    0.689\n",
      "    item_3            1.000                               0.253    0.664\n",
      "    item_4            1.000                               0.253    0.656\n",
      "    item_5            1.000                               0.253    0.657\n",
      "    item_6            1.000                               0.253    0.650\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            1.504    0.024   62.432    0.000    1.504    4.047\n",
      "   .item_2            1.423    0.024   59.697    0.000    1.423    3.870\n",
      "   .item_3            1.392    0.025   56.265    0.000    1.392    3.647\n",
      "   .item_4            1.305    0.025   52.077    0.000    1.305    3.376\n",
      "   .item_5            1.346    0.025   53.815    0.000    1.346    3.488\n",
      "   .item_6            1.306    0.025   51.677    0.000    1.306    3.350\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            0.074    0.008    9.254    0.000    0.074    0.535\n",
      "   .item_2            0.071    0.008    9.186    0.000    0.071    0.525\n",
      "   .item_3            0.081    0.009    9.410    0.000    0.081    0.559\n",
      "   .item_4            0.085    0.009    9.475    0.000    0.085    0.570\n",
      "   .item_5            0.085    0.009    9.468    0.000    0.085    0.569\n",
      "   .item_6            0.088    0.009    9.518    0.000    0.088    0.577\n",
      "    eta               0.064    0.007    9.004    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "ro.r(\"mete <<-'eta=~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6'\")\n",
    "# Fit the model\n",
    "ro.r('fitmete <- sem(mete, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n",
    "# Print the output of the model for interpretation\n",
    "summary_fitmete = ro.r(\"summary(fitmete, fit.measures=TRUE, standardized=TRUE)\")\n",
    "print(summary_fitmete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70a662",
   "metadata": {},
   "source": [
    "You can see that the output looks very similar to the one from the **Tau Congeneric** measurement model. The interpretation of the intercepts (`Intecepts` section) and for the errors (`Variances` section) is the same as before. The only difference is that the loadings (`Latent Variables` section) are all fixed to one, meaning that we assume that all items have the same discriminatory power. Graphically speaking, this means that the slopes of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "Next, lets compare the models we just fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cae00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC   Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)\n",
      "fitmtc   9 900.36 962.86  9.5683                                       \n",
      "fitmete 14 897.74 942.88 16.9488     7.3805 0.044726       5     0.1938\n",
      "\n",
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC   Chisq Chisq diff    RMSEA Df diff Pr(>Chisq)\n",
      "fitmtc   9 900.36 962.86  9.5683                                       \n",
      "fitmete 14 897.74 942.88 16.9488     7.3805 0.044726       5     0.1938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform anova and print indexes\n",
    "anova_mete_mtc = ro.r(\"anova(fitmete, fitmtc)\")\n",
    "lavTestLRT_mete_mtc = ro.r(\"lavTestLRT(fitmete, fitmtc)\")\n",
    "print(anova_mete_mtc)\n",
    "print(lavTestLRT_mete_mtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eec3fa",
   "metadata": {},
   "source": [
    "According to the BIC and AIC the more restricted **Essentially tau-equivalent** model has a better model fit compared to the **Tau Congeneric** measurement model (as lower values for AIC and BIC indicate better model fit). The $\\chi^2$ Test however suggests that there are no significant differences in model fit as indicated by p > .05. This result is not too surprising as we already saw quite similar loading estimates across items in the **Tau Congeneric** measurement model (see above). Therefore, restricting the loadings to equivalence isn't too much of a deviation from the **Tau Congeneric** measurement model (which does not restrict the loadings), resulting in a insignificant difference in model fit.\n",
    "\n",
    "## Tau-Equivalent Model\n",
    "\n",
    "The **Tau-equivalent** measurement model has one more restriction compared to the **Essentially tau-equivalent** model. It assumes that\n",
    "\n",
    "* items **are equivalent in their difficulty**\n",
    "* items **are equivalent in their discrimination power**\n",
    "* items are differently reliable  \n",
    "\n",
    "We therefore only get an estimate for the errors (`Variances` section). Note that we also get a `Latent Variables` section and\n",
    "a `Intecepts` section again, however, you can see that all the loadings and intercepts are fixed.\n",
    "\n",
    "## Fit the model and a quick rpy2 hint\n",
    "\n",
    "Using `rpy2` to Define Multi-Line Lavaan Models in R  \n",
    "\n",
    "When working with `rpy2` in Python to execute R commands, multi-line strings must be formatted correctly. R's **lavaan** package requires structured model definitions, but Python's `rpy2` only accepts single-line strings. To maintain readability and correctness, **`\\n`** is used to preserve line breaks.\n",
    "\n",
    "### **Example: Defining a Latent Variable Model in R**  \n",
    "\n",
    "```python\n",
    "ro.r(\"mte <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n",
    "      \"item_1 ~ a*1\\n\"\n",
    "      \"item_2 ~ a*1\\n\"\n",
    "      \"item_3 ~ a*1\\n\"\n",
    "      \"item_4 ~ a*1\\n\"\n",
    "      \"item_5 ~ a*1\\n\"\n",
    "      \"item_6 ~ a*1'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba081c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavaan 0.6-19 ended normally after 13 iterations\n",
      "\n",
      "  Estimator                                         ML\n",
      "  Optimization method                           NLMINB\n",
      "  Number of model parameters                        13\n",
      "  Number of equality constraints                     5\n",
      "\n",
      "  Number of observations                           238\n",
      "\n",
      "Model Test User Model:\n",
      "                                                      \n",
      "  Test statistic                               100.116\n",
      "  Degrees of freedom                                19\n",
      "  P-value (Chi-square)                           0.000\n",
      "\n",
      "Model Test Baseline Model:\n",
      "\n",
      "  Test statistic                               435.847\n",
      "  Degrees of freedom                                15\n",
      "  P-value                                        0.000\n",
      "\n",
      "User Model versus Baseline Model:\n",
      "\n",
      "  Comparative Fit Index (CFI)                    0.807\n",
      "  Tucker-Lewis Index (TLI)                       0.848\n",
      "\n",
      "Loglikelihood and Information Criteria:\n",
      "\n",
      "  Loglikelihood user model (H0)               -477.454\n",
      "  Loglikelihood unrestricted model (H1)       -427.396\n",
      "                                                      \n",
      "  Akaike (AIC)                                 970.908\n",
      "  Bayesian (BIC)                               998.686\n",
      "  Sample-size adjusted Bayesian (SABIC)        973.329\n",
      "\n",
      "Root Mean Square Error of Approximation:\n",
      "\n",
      "  RMSEA                                          0.134\n",
      "  90 Percent confidence interval - lower         0.109\n",
      "  90 Percent confidence interval - upper         0.160\n",
      "  P-value H_0: RMSEA <= 0.050                    0.000\n",
      "  P-value H_0: RMSEA >= 0.080                    1.000\n",
      "\n",
      "Standardized Root Mean Square Residual:\n",
      "\n",
      "  SRMR                                           0.111\n",
      "\n",
      "Parameter Estimates:\n",
      "\n",
      "  Standard errors                             Standard\n",
      "  Information                                 Expected\n",
      "  Information saturated (h1) model          Structured\n",
      "\n",
      "Latent Variables:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "  eta =~                                                                \n",
      "    item_1            1.000                               0.252    0.637\n",
      "    item_2            1.000                               0.252    0.683\n",
      "    item_3            1.000                               0.252    0.663\n",
      "    item_4            1.000                               0.252    0.639\n",
      "    item_5            1.000                               0.252    0.655\n",
      "    item_6            1.000                               0.252    0.634\n",
      "\n",
      "Intercepts:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1     (a)    1.381    0.018   76.284    0.000    1.381    3.485\n",
      "   .item_2     (a)    1.381    0.018   76.284    0.000    1.381    3.736\n",
      "   .item_3     (a)    1.381    0.018   76.284    0.000    1.381    3.630\n",
      "   .item_4     (a)    1.381    0.018   76.284    0.000    1.381    3.496\n",
      "   .item_5     (a)    1.381    0.018   76.284    0.000    1.381    3.585\n",
      "   .item_6     (a)    1.381    0.018   76.284    0.000    1.381    3.471\n",
      "\n",
      "Variances:\n",
      "                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n",
      "   .item_1            0.093    0.010    9.529    0.000    0.093    0.594\n",
      "   .item_2            0.073    0.008    9.138    0.000    0.073    0.534\n",
      "   .item_3            0.081    0.009    9.318    0.000    0.081    0.560\n",
      "   .item_4            0.092    0.010    9.513    0.000    0.092    0.592\n",
      "   .item_5            0.085    0.009    9.387    0.000    0.085    0.571\n",
      "   .item_6            0.095    0.010    9.548    0.000    0.095    0.598\n",
      "    eta               0.064    0.007    8.880    0.000    1.000    1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "ro.r(\"mte <<- 'eta =~ item_1 + 1*item_2 + 1*item_3 + 1*item_4 + 1*item_5 + 1*item_6\\n\"\n",
    "      \"item_1 ~ a*1\\n\"\n",
    "      \"item_2 ~ a*1\\n\"\n",
    "      \"item_3 ~ a*1\\n\"\n",
    "      \"item_4 ~ a*1\\n\"\n",
    "      \"item_5 ~ a*1\\n\"\n",
    "      \"item_6 ~ a*1'\")\n",
    "\n",
    "# Fit the model\n",
    "ro.r('fitmte <- sem(mte, data=dat2, meanstructure=TRUE, estimator=\"ML\")')\n",
    "# Print the output of the model for interpretation\n",
    "summary_fitmte = ro.r(\"summary(fitmte, fit.measures=TRUE, standardized=TRUE)\")\n",
    "print(summary_fitmte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addbcc35",
   "metadata": {},
   "source": [
    "Again, the output looks very similar to the previous ones. The interpretation also is equivalent to before. The only difference is that the loadings (`Latent Variables` section) and the intercept (`Intercepts` section) are fixed, meaning that we assume that all items have the same discriminatory power and the same difficulty. Graphically speaking, this means that the slopes and the intercepts of the items are equivalent. The interpretation of the fit indices is analogous to the **Tau Congeneric** measurement model (see above).\n",
    "\n",
    "### Compare model fit\n",
    "\n",
    "As before, we can use the `anova()` function to compare the model fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-Squared Difference Test\n",
      "\n",
      "        Df    AIC    BIC   Chisq Chisq diff   RMSEA Df diff Pr(>Chisq)    \n",
      "fitmete 14 897.74 942.88  16.949                                          \n",
      "fitmte  19 970.91 998.69 100.116     83.168 0.25629       5  < 2.2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform anova and print indexes\n",
    "anova_mete_mte = ro.r(\"anova(fitmete, fitmte)\")\n",
    "print(anova_mete_mte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e2f6a",
   "metadata": {},
   "source": [
    "In this comparison, the more restricted Tau-equivalent model has significantly worse fit compared to the Essentially tau-equivalent model as indicated by the significant differences in $\\chi^2$. Also AIC and BIC favor the more flexible model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
